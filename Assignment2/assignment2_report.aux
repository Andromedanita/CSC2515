\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces }}{1}{figure.1}}
\newlabel{fig:Q3_valid_combined}{{1}{1}{}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {epsilon=0.01}, CE on the left and accuracy on the right for both validation and training sets.}}{2}{figure.2}}
\newlabel{fig:refer1}{{2}{2}{\textbf {epsilon=0.01}, CE on the left and accuracy on the right for both validation and training sets}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {epsilon=1.0}, CE on the left and accuracy on the right for both validation and training sets.}}{2}{figure.3}}
\newlabel{fig:refer2}{{3}{2}{\textbf {epsilon=1.0}, CE on the left and accuracy on the right for both validation and training sets}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {epsilon=1.0}, CE on the left and accuracy on the right for both validation and training sets for three different momentum values while keeping \textbf  {epsilon=0.01}. The momentum values are 0.0, 0.5 and 0.9 from top to the bottom.}}{3}{figure.4}}
\newlabel{fig:refer2}{{4}{3}{\textbf {epsilon=1.0}, CE on the left and accuracy on the right for both validation and training sets for three different momentum values while keeping \textbf {epsilon=0.01}. The momentum values are 0.0, 0.5 and 0.9 from top to the bottom}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {epsilon=0.01, momentum=0.0, batch size=1}}}{3}{figure.5}}
\newlabel{fig:Q32_batch10}{{5}{3}{\textbf {epsilon=0.01, momentum=0.0, batch size=1}}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {epsilon=0.01, momentum=0.0, batch size=10}}}{4}{figure.6}}
\newlabel{fig:Q32_batch10}{{6}{4}{\textbf {epsilon=0.01, momentum=0.0, batch size=10}}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {epsilon=0.01, momentum=0.0, batch size=100}}}{4}{figure.7}}
\newlabel{fig:Q32_batch10}{{7}{4}{\textbf {epsilon=0.01, momentum=0.0, batch size=100}}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textbf  {epsilon=0.01, momentum=0.0, batch size=500}}}{4}{figure.8}}
\newlabel{fig:Q32_batch10}{{8}{4}{\textbf {epsilon=0.01, momentum=0.0, batch size=500}}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \textbf  {epsilon=0.01, momentum=0.0, batch size=1000}}}{4}{figure.9}}
\newlabel{fig:Q32_batch10}{{9}{4}{\textbf {epsilon=0.01, momentum=0.0, batch size=1000}}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Log-likelihood as a function of number of iterations for different values of randConst parameter.}}{5}{figure.10}}
\newlabel{fig:q4_log_iter}{{10}{5}{Log-likelihood as a function of number of iterations for different values of randConst parameter}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Mean of the images- Is is blurry because it is average.}}{6}{figure.11}}
\newlabel{fig:q4.2_mu}{{11}{6}{Mean of the images- Is is blurry because it is average}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Variance of the images-black means lower variance and white means higher variance.}}{6}{figure.12}}
\newlabel{fig:q4.2_vary}{{12}{6}{Variance of the images-black means lower variance and white means higher variance}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Value of mixture of coefficients for each cluster.}}{7}{figure.13}}
\newlabel{fig:q4.2_pik}{{13}{7}{Value of mixture of coefficients for each cluster}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Comparison between log-likelihood using two different methods: Kmeans shown in magenta and randomized method (using randConst) shown in blue. We can see that using means method the log-likelihood converges earlier to a similar value compared to the randomized method.}}{7}{figure.14}}
\newlabel{fig:q4.3_logL}{{14}{7}{Comparison between log-likelihood using two different methods: Kmeans shown in magenta and randomized method (using randConst) shown in blue. We can see that using means method the log-likelihood converges earlier to a similar value compared to the randomized method}{figure.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces }}{8}{figure.15}}
\newlabel{fig:q4.3_mu}{{15}{8}{}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces }}{8}{figure.16}}
\newlabel{fig:q4.3_mu}{{16}{8}{}{figure.16}{}}
\newlabel{eq:bayes}{{1}{8}{4.4}{equation.0.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces }}{9}{figure.17}}
\newlabel{fig:4.4}{{17}{9}{}{figure.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces }}{9}{figure.18}}
\newlabel{fig:err_rate}{{18}{9}{}{figure.18}{}}
